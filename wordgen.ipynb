{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20430d34",
   "metadata": {},
   "source": [
    "•\tRandom Word Generation: Selecting words randomly from a predefined word corpus (dictionary) like the NLTK words dataset. \n",
    "•\tWord Validity Check: Verifying if a word exists in a dictionary corpus. \n",
    "•\tGenerating Words from Characters: Creating possible words by permuting given characters and filtering valid ones. \n",
    "•\tAdding Prefixes and Suffixes: Modifying words by attaching common prefixes (e.g., \"un-\", \"pre-\") or suffixes (e.g., \"-ing\", \"-ness\") and checking if they form real words. \n",
    "•\tExtracting Unique Words & Computing Word Length: Filtering words by removing stopwords (common words like \"the\", \"is\") and punctuation, then measuring word length statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ba49733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "743924df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\divya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('words')\n",
    "word_list= nltk.corpus.words.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "766b2e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['supercabinet', 'refectorial', 'supererogator', 'omninescience', 'Faliscan', 'supramental', 'craggy', 'noncontributor', 'radiescent', 'possessed']\n"
     ]
    }
   ],
   "source": [
    "n = int(input(\"Enter the number of random words you want: \"))\n",
    "random_word= random.sample(word_list,n)\n",
    "print(random_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8cca783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid word\n"
     ]
    }
   ],
   "source": [
    "word= input(\"Enter a word: \")\n",
    "if word in word_list:\n",
    "    print(\"valid word\")\n",
    "else:\n",
    "    print(\"invalid word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "494fea99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'act', 'sec', 'ear', 'ras', 'eta', 'car', 'are', 'rea', 'tar', 'tea', 'arc', 'tra', 'ace', 'tec', 'cat', 'art', 'era', 'set', 'tst', 'sea', 'sac', 'sar', 'ers', 'ate', 'ser', 'tae', 'sat', 'ast', 'aes', 'ase', 'aer', 'rat', 'eat', 'tat', 'ret'}\n"
     ]
    }
   ],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "def generatewords(word,length):\n",
    "    return [''.join(p)for p in permutations(word,length) if ''.join(p).lower() in set(word_list) ]\n",
    "word= input(\"Enter a word: \")\n",
    "length= int(input(\"Enter the length of the word: \"))\n",
    "words= generatewords(word,length)\n",
    "print(set(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfb59abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid words with prefixes/suffixes:  {'comforter', 'recomfort', 'discomfort', 'comforting', 'uncomfort'}\n"
     ]
    }
   ],
   "source": [
    "# Define some common prefixes and suffixes (can be extended)\n",
    "prefixes = ['un', 're', 'dis', 'in', 'im']\n",
    "suffixes = ['ed', 'ing', 'es', 'er', 'ly']\n",
    "word= input(\"Enter a word: \")\n",
    "valid= set()\n",
    "\n",
    "for prefix in prefixes:\n",
    "    new_word= prefix+ word\n",
    "    if new_word in word_list:\n",
    "        valid.add(new_word)\n",
    "for suffix in suffixes:\n",
    "    new_word= word+ suffix\n",
    "    if new_word in word_list:\n",
    "        valid.add(new_word)\n",
    "print(\"Valid words with prefixes/suffixes: \", valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "088b2b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\divya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\brown.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\divya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words: 49621\n",
      "Average word length: 8.09\n",
      "Minimum word length: 1\n",
      "Maximum word length: 33\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.corpus import brown, stopwords\n",
    "import string\n",
    "\n",
    "# Download required NLTK datasets\n",
    "nltk.download('brown')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Define stopwords and punctuation\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "# Extract words from the Brown corpus\n",
    "words = brown.words()\n",
    "\n",
    "# Filter words: Remove stopwords and punctuation\n",
    "filtered_words = [word.lower() for word in words if word.lower() not in stop_words and word not in punctuation]\n",
    "\n",
    "# Extract unique words\n",
    "unique_words = set(filtered_words)\n",
    "\n",
    "# Compute word length statistics\n",
    "word_lengths = [len(word) for word in unique_words]\n",
    "average_length = sum(word_lengths) / len(word_lengths) if word_lengths else 0\n",
    "min_length = min(word_lengths) if word_lengths else 0\n",
    "max_length = max(word_lengths) if word_lengths else 0\n",
    "\n",
    "# Output the statistics\n",
    "print(f\"Total unique words: {len(unique_words)}\")\n",
    "print(f\"Average word length: {average_length:.2f}\")\n",
    "print(f\"Minimum word length: {min_length}\")\n",
    "print(f\"Maximum word length: {max_length}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80494ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
